{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic\n",
    "\n",
    "Patrick ðŸŒ°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lipengyuan/anaconda3/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_9.4.1) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('Datasets/train.csv')\n",
    "test_df = pd.read_csv('Datasets/test.csv')\n",
    "combine_df = pd.read_csv('Datasets/combine.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Find good-performance models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = combine_df.iloc[:891,:].drop([\"PassengerId\",\"Survived\"], axis=1)\n",
    "Y_all = combine_df.iloc[:891,:][\"Survived\"]\n",
    "X_test = combine_df.iloc[891:,:].drop([\"PassengerId\",\"Survived\"], axis=1)\n",
    "\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "svc = SVC()\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "random_forest = RandomForestClassifier(n_estimators=300,min_samples_leaf=4,class_weight={0:0.745,1:0.255})\n",
    "gbdt = GradientBoostingClassifier(n_estimators=500,learning_rate=0.03,max_depth=3)\n",
    "# xgb = XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.03)\n",
    "xgb = XGBClassifier(learning_rate=0.05, max_depth= 2, n_estimators= 280)\n",
    "lgb = LGBMClassifier(max_depth=3, n_estimators=500, learning_rate=0.02)\n",
    "clfs = [logreg, svc, knn, decision_tree, random_forest, gbdt, xgb, lgb]\n",
    "\n",
    "\n",
    "kfold = 10\n",
    "cv_results = []\n",
    "for classifier in clfs :\n",
    "    cv_results.append(cross_val_score(classifier, X_all.values, y = Y_all.values, scoring = \"accuracy\", cv = kfold, n_jobs=-1))\n",
    "\n",
    "    \n",
    "cv_means = []\n",
    "cv_std = []\n",
    "for cv_result in cv_results:\n",
    "    cv_means.append(cv_result.mean())\n",
    "    cv_std.append(cv_result.std())\n",
    "ag = [\"LR\",\"SVC\",'KNN','decision_tree',\"random_forest\",\"GBDT\",\"xgbGBDT\", \"LGB\"]\n",
    "cv_res = pd.DataFrame({\"CrossValMeans\":cv_means,\"CrossValerrors\": cv_std,\n",
    "                       \"Algorithm\":ag})\n",
    "\n",
    "\n",
    "g = sns.barplot(\"CrossValMeans\",\"Algorithm\",data = cv_res, palette=\"Set3\",orient = \"h\",**{'xerr':cv_std})\n",
    "g.set_xlabel(\"Mean Accuracy\")\n",
    "g = g.set_title(\"Cross validation scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR 0.8730793893996142\n",
      "SVC 0.8674489274770174\n",
      "KNN 0.8506829531267733\n",
      "decision_tree 0.8652142208602884\n",
      "random_forest 0.8620570877312451\n",
      "GBDT 0.8843408807172851\n",
      "xgbGBDT 0.8854267393031439\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    print(ag[i],cv_means[i])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
